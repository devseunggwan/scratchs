{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "from lightning_whisper_mlx import LightningWhisperMLX\n",
    "from tqdm import tqdm\n",
    "\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_json(data, filename):\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(data, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 음성 데이터 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"large-v3\"\n",
    "\n",
    "path_voice = \"./data/voices\"\n",
    "list_voice = tqdm(os.listdir(path_voice))\n",
    "\n",
    "whisper = LightningWhisperMLX(model=model, batch_size=12, quant=None)\n",
    "result = []\n",
    "\n",
    "for voice_file in list_voice:\n",
    "    list_voice.set_description(voice_file)\n",
    "\n",
    "    path_voice_file = os.path.join(path_voice, voice_file)\n",
    "    translate = whisper.transcribe(audio_path=path_voice_file)\n",
    "\n",
    "    resp = {\"file_name\": voice_file, \"original\": translate}\n",
    "\n",
    "    write_json(resp, f\"./data/output/{voice_file}.json\")\n",
    "    result.append(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "\n",
    "df = duckdb.query(\"SELECT * FROM './data/output/*.json'\").df()\n",
    "\n",
    "df_file_name = df[\"file_name\"]\n",
    "df = pd.json_normalize(df[\"original\"])\n",
    "df = pd.concat([df_file_name, df], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[~df[\"language\"].str.contains(\"ko\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del df[\"segments\"]\n",
    "\n",
    "df.to_csv(\"./data/output.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 개인정보 마스킹 프롬프트 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_system = \"\"\"\n",
    "<요청사항>\n",
    "- 당신은 개인정보 보호를 위해 수정 요청을 받았습니다.\n",
    "- 답변은 한국어(korean)로 작성 부탁드립니다.\n",
    "- <검토 내용>을 확인하고 개인정보라고 판단되는 내용을 마스킹합니다. \n",
    "- 마스킹은 별표(*)로만 처리하고 개인정보를 지우셔야 됩니다. (예시: 홍길동 -> ***)\n",
    "- 마스킹 후 <검토 내용> 전문 전체를 마스킹이 된 답변으로 제공해야 합니다.\n",
    "- 미스킹을 하지않고 답변을 낼 경우 개인정보 보호법에 위반될 수 있습니다.\n",
    "- 검토 내용을 요약하지 마세요\n",
    "\n",
    "<마스킹해야 하는 개인정보 목록>\n",
    "- 이름, 주민등록번호, 연락처, 주소, 이메일주소, 계좌번호, 신용카드번호, 생년월일, 성별, 소속, 사업자등록번호\n",
    "\"\"\"\n",
    "\n",
    "prompt_user = \"\"\"\n",
    "이하 내용 검토 후 한국어로 작성 부탁드립니다.\n",
    "\n",
    "<검토 내용>\n",
    "{input}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(model=\"solar\")\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", prompt_system),\n",
    "        (\"human\", prompt_user),\n",
    "    ]\n",
    ")\n",
    "chain = prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/voc-result-whisper-large-v3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df.iloc[random.randint(0, len(df))][\"text\"]\n",
    "print(chain.invoke({\"input\": text}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 내용 추출 프롬프트 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "콜센터에서 고객과의 음성대화를 텍스트로 변환한 데이터를 제공할겁니다.\n",
    "이에 대해서 출력형태에 맞게 작성해주세요.\n",
    "\n",
    "<요청 사항>\n",
    "- 답변은 한국어(korean)로 작성해주세요.\n",
    "- 요약 문장은 상세하게 작성해주세요.\n",
    "- 카테고리는 대화에 가장 어올리는 주제로 잡아주세요.\n",
    "- 태그는 대화에 가장 어올리는 주제로 잡아주세요.\n",
    "- 감정 분석에서 대화에서 고객이 느끼고 있는 감정 5가지를 작성해주세요.\n",
    "- 감정 5가지 작성 이후 고객의 감정을 설명해주세요.\n",
    "\n",
    "<제공 텍스트>\n",
    "{input}\n",
    "\n",
    "<출력 형태>\n",
    "\n",
    "### **제목: [대화 제목]**\n",
    "\n",
    "- [요약 문장 1]\n",
    "- [요약 문장 2]\n",
    "- [요약 문장 3]\n",
    "- [요약 문장 4]\n",
    "- [요약 문장 5]\n",
    "\n",
    "### 카테고리\n",
    "\n",
    "- [카테고리 1], [카테고리 2], [카테고리 3], [카테고리 4], [카테고리 5]\n",
    "\n",
    "### 태그\n",
    "\n",
    "- [태그 1], [태그 2], [태그 3], [태그 4], [태그 5]\n",
    "\n",
    "### 감정 분석\n",
    "\n",
    "- [감정 1], [감정 2], [감정 3], [감정 4], [감정 5]\n",
    "- [고객의 감정 설명]\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "llm = ChatOllama(model=\"mistral\")\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", template),\n",
    "    ]\n",
    ")\n",
    "chain = prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/voc-result-whisper-large-v3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df.iloc[random.randint(0, len(df))][\"text\"]\n",
    "print(chain.invoke({\"input\": text}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df.iloc[random.randint(0, len(df))][\"text\"]\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DIL 라이브러리 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/voc-result-whisper-large-v3.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DIL import Suppression\n",
    "\n",
    "sup = Suppression(df)\n",
    "\n",
    "result = sup.general(columns=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./data/DIL_output.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas로 전처리하는 걸 굳이 추상화한 것 같은데 굳이... 원하는 라이브러리가 아님"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 직접 라벨링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in df.iterrows():\n",
    "    print(row[\"file_name\"])\n",
    "    for i in range(0, len(row[\"text\"]), 100):\n",
    "        print(row[\"text\"][i : i + 100])\n",
    "\n",
    "    print(\"-----------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
