{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import boto3\n",
    "import pandas as pd\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = boto3.client(\n",
    "    \"s3\",\n",
    "    aws_access_key_id=os.getenv(\"AWS_ACCESS_KEY_ID\"),\n",
    "    aws_secret_access_key=os.getenv(\"AWS_SECRET_ACCESS_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET_NAME = \"\"\n",
    "BASE_SOURCE_KEY = \"\"\n",
    "BASE_DESTINATION_KEY = \"\"\n",
    "\n",
    "NETWORKS = []\n",
    "DAYS = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for network in NETWORKS:\n",
    "    response = s3_client.list_objects_v2(\n",
    "        Bucket=BUCKET_NAME,\n",
    "        Prefix=os.path.join(BASE_SOURCE_KEY, f\"{network}/\"),\n",
    "        Delimiter=\"/\",\n",
    "    )\n",
    "\n",
    "    folders = [folder[\"Prefix\"] for folder in response.get(\"CommonPrefixes\", [])]\n",
    "\n",
    "    for folder in folders:\n",
    "        for day in DAYS:\n",
    "            source_path = os.path.join(folder, day)\n",
    "            dest_path = source_path.replace(\"opensea\", \"opensea_v2\")\n",
    "\n",
    "            for file in s3_client.list_objects_v2(\n",
    "                Bucket=BUCKET_NAME, Prefix=source_path\n",
    "            ).get(\"Contents\", []):\n",
    "                try:\n",
    "                    file_name = file[\"Key\"].split(\"/\")[-1]\n",
    "\n",
    "                    response = s3_client.get_object(Bucket=BUCKET_NAME, Key=file[\"Key\"])\n",
    "                    json_data = response[\"Body\"].read().decode(\"utf-8\")\n",
    "                    data = json.loads(json_data)\n",
    "                    df = pd.DataFrame(data)\n",
    "\n",
    "                    df[\"volume\"] = pd.to_numeric(df[\"volume\"], errors=\"raise\")\n",
    "                    df[\"volumeUsd\"] = pd.to_numeric(df[\"volumeUsd\"], errors=\"raise\")\n",
    "                    df[\"volumeKrw\"] = pd.to_numeric(df[\"volumeKrw\"], errors=\"raise\")\n",
    "\n",
    "                    df[\"floorprice\"] = pd.to_numeric(df[\"floorprice\"], errors=\"raise\")\n",
    "                    df[\"floorpriceEth\"] = pd.to_numeric(\n",
    "                        df[\"floorpriceEth\"], errors=\"raise\"\n",
    "                    )\n",
    "                    df[\"floorpriceUsd\"] = pd.to_numeric(\n",
    "                        df[\"floorpriceUsd\"], errors=\"raise\"\n",
    "                    )\n",
    "                    df[\"floorpriceKrw\"] = pd.to_numeric(\n",
    "                        df[\"floorpriceKrw\"], errors=\"raise\"\n",
    "                    )\n",
    "\n",
    "                    df[\"totalSupply\"] = pd.to_numeric(df[\"totalSupply\"], errors=\"raise\")\n",
    "\n",
    "                    df.to_parquet(\"temp.parquet\", compression=\"gzip\")\n",
    "\n",
    "                    s3_client.upload_file(\n",
    "                        \"temp.parquet\",\n",
    "                        BUCKET_NAME,\n",
    "                        os.path.join(dest_path, file_name.replace(\".json\", \".parquet\")),\n",
    "                    )\n",
    "                except Exception as E:\n",
    "                    print(f\"Error processing {file['Key']}\", E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_errors = pd.read_csv(\"./data/errors.csv\", sep=\" \", header=None)\n",
    "df_errors_polygon = df_errors[2].loc[df_errors[2].str.contains(\"polygon\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_key in df_errors_polygon:\n",
    "    try:\n",
    "        response = s3_client.get_object(Bucket=BUCKET_NAME, Key=file_key)\n",
    "        json_data = response[\"Body\"].read().decode(\"utf-8\")\n",
    "        data = json.loads(json_data)\n",
    "        df = pd.DataFrame(data)\n",
    "\n",
    "        df[\"volume\"] = pd.to_numeric(df[\"volume\"], errors=\"raise\")\n",
    "        df[\"volumeUsd\"] = pd.to_numeric(df[\"volumeUsd\"], errors=\"raise\")\n",
    "        df[\"volumeKrw\"] = pd.to_numeric(df[\"volumeKrw\"], errors=\"raise\")\n",
    "\n",
    "        df[\"floorprice\"] = pd.to_numeric(df[\"floorprice\"], errors=\"raise\")\n",
    "        df[\"floorpriceEth\"] = pd.to_numeric(df[\"floorpriceEth\"], errors=\"raise\")\n",
    "        df[\"floorpriceUsd\"] = pd.to_numeric(df[\"floorpriceUsd\"], errors=\"raise\")\n",
    "        df[\"floorpriceKrw\"] = pd.to_numeric(df[\"floorpriceKrw\"], errors=\"raise\")\n",
    "\n",
    "        df[\"totalSupply\"] = pd.to_numeric(df[\"totalSupply\"], errors=\"raise\")\n",
    "\n",
    "        df.to_parquet(\"temp.parquet\", compression=\"gzip\")\n",
    "\n",
    "        s3_client.upload_file(\n",
    "            \"temp.parquet\",\n",
    "            BUCKET_NAME,\n",
    "            file_key.replace(\"json\", \"parquet\").replace(\"opensea\", \"opensea_v2\"),\n",
    "        )\n",
    "        # print(f\"Successfully processed {file_key.replace('json', 'parquet').replace('opensea', 'opensea_v2')}\")\n",
    "    except Exception as E:\n",
    "        print(f\"Error processing {file_key}\", E)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
