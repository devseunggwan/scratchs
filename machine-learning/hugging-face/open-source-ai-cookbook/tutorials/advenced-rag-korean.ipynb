{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "\n",
    "import chromadb\n",
    "import nltk\n",
    "import pacmap\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import torch\n",
    "from langchain import PromptTemplate\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders.url import UnstructuredURLLoader\n",
    "from langchain_community.vectorstores.utils import DistanceStrategy\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문서 로드 & 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"averaged_perceptron_tagger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = \"v4.49.0\"\n",
    "\n",
    "urls = [\n",
    "    f\"https://huggingface.co/docs/transformers/{version}/ko/pipeline_tutorial\",\n",
    "    f\"https://huggingface.co/docs/transformers/{version}/ko/autoclass_tutorial\",\n",
    "    f\"https://huggingface.co/docs/transformers/{version}/ko/preprocessing\",\n",
    "    f\"https://huggingface.co/docs/transformers/{version}/ko/training\",\n",
    "    f\"https://huggingface.co/docs/transformers/{version}/ko/run_scripts\",\n",
    "    f\"https://huggingface.co/docs/transformers/{version}/ko/tokenizer_summary\",\n",
    "    f\"https://huggingface.co/docs/transformers/{version}/ko/attention\",\n",
    "    f\"https://huggingface.co/docs/transformers/{version}/ko/pad_truncation\",\n",
    "    f\"https://huggingface.co/docs/transformers/{version}/ko/pipeline_webserver\",\n",
    "    f\"https://huggingface.co/docs/transformers/{version}/ko/tasks_explained\",\n",
    "    f\"https://huggingface.co/docs/transformers/{version}/ko/hpo_train\",\n",
    "    f\"https://huggingface.co/docs/transformers/{version}/ko/tasks/sequence_classification\",\n",
    "    f\"https://huggingface.co/docs/transformers/{version}/ko/tasks/token_classification\",\n",
    "    f\"https://huggingface.co/docs/transformers/{version}/ko/tasks/question_answering\",\n",
    "    f\"https://huggingface.co/docs/transformers/{version}/ko/tasks/language_modeling\",\n",
    "    f\"https://huggingface.co/docs/transformers/{version}/ko/tasks/masked_language_modeling\",\n",
    "    f\"https://huggingface.co/docs/transformers/{version}/ko/tasks/translation\",\n",
    "    f\"https://huggingface.co/docs/transformers/{version}/ko/tasks/summarization\",\n",
    "]\n",
    "loader = UnstructuredURLLoader(urls=urls, show_progress_bar=True)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs[0].page_content.split(\"→\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "튜토리얼에 나온 것처럼 ToC를 사용하고 싶었는데 \n",
    "UnstructuredURLLoader에서 ToC까지 가져오지 못함\n",
    "\"\"\"\n",
    "\n",
    "for doc in docs:\n",
    "    doc.page_content = doc.page_content.split(\"to get started\\n\\n\")[-1].split(\"< > Update on GitHub\\n\\n\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=embedding_model_name,\n",
    "    encode_kwargs={\"normalize_embeddings\": True}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_name = \"collection_huggingface_transformer\"\n",
    "\n",
    "vector_store = Chroma(\n",
    "    collection_name=collection_name,\n",
    "    embedding_function=embedding_model,\n",
    "    persist_directory=\"./chroma.db\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uuids = [str(uuid4()) for _ in range(len(docs))]\n",
    "vector_store.add_documents(documents=docs, ids=uuids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.get(\"2c92b8f5-6786-4d9a-9b9f-cc094911979b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.delete_collection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"pipeline이 무엇인지 알려줘.\"\n",
    "\n",
    "retriever = vector_store.similarity_search(\n",
    "    user_query,\n",
    "    k=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 프롬프트 & 체인 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "    <|begin_of_text|>\n",
    "    <|start_header_id|>system<|end_header_id|>\n",
    "    당신은 QA(Question-Answering)을 수행하는 Assistant입니다. 다음의 Context를 이용하여 Question에 답변하세요.\n",
    "    최소 3문장 최대 5문장으로 답변하세요.\n",
    "    주어진 Context가 없다면 \"정보가 부족하여 답변할 수 없습니다.\"를 출력하세요.\n",
    "    <|eot_id|>\n",
    "    <|start_header_id|>user<|end_header_id|>\n",
    "    Context: {context}\n",
    "    Question: {question}\n",
    "    <|eot_id|>\n",
    "    <|start_header_id|>assistant<|end_header_id|>\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "    \n",
    "prompt = PromptTemplate(input_variables=[\"context\", \"question\"], template=template)\n",
    "prompt.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    print(docs)\n",
    "    \n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "READER_MODEL_NAME = \"yanolja/EEVE-Korean-Instruct-10.8B-v1.0\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    llm_int8_enable_fp32_cpu_offload=True\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(READER_MODEL_NAME)\n",
    "tokenizer = AutoTokenizer.from_pretrained(READER_MODEL_NAME)\n",
    "\n",
    "READER_LLM = pipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    task=\"text-generation\",\n",
    "    do_sample=True,\n",
    "    temperature=0.2,\n",
    "    repetition_penalty=1.1,\n",
    "    return_full_text=False,\n",
    "    max_new_token=500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = HuggingFacePipeline(pipeline=READER_LLM)\n",
    "rag_chain = {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()} | prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Hugging Face Transformers에서 pipeline은 어떤 매개변수를 사용해? 코드도 알려줘.\"\n",
    "result = rag_chain.invoke(question)\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
